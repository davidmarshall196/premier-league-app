import pandas as pd
import numpy as np
import sys
sys.path.append('../')
from premier_league import (
    constants,
    data_extraction,
    preprocessing,
    prediction,
    visualisations,
    s3_helpers,
    mlflow_functions,
    postgres
)
if constants.RUN_DATA_EXPECTATIONS:
    from premier_league.expectations_helpers import (
        AutoGreatExpectations,
        view_full_suite,
        view_suite_summary,
        save_expectations,
        load_expectations,
        validate_data
    )
import joblib
from tabulate import tabulate
import runpy
import shap
import matplotlib.pyplot as plt
from mlflow.tracking import MlflowClient


import importlib
importlib.reload(prediction)
importlib.reload(visualisations)
importlib.reload(constants)
importlib.reload(data_extraction)





if constants.RUN_DATA_EXPECTATIONS:
    data_expectations = load_expectations(constants.exp_loc)


if constants.INITIAL_DATA_LOAD:
    full_data = data_extraction.load_all_data(
        constants.TRAINING_DATA_LOCATION,
        constants.COLUMNS_REQ
    )
else:
    full_data = s3_helpers.grab_data_s3(
        constants.TRAINING_DATA_LOCATION)



full_data = data_extraction.add_new_data(
    full_data, 
    constants.COLUMNS_REQ,
    constants.TRAINING_DATA_LOCATION
)


full_data = data_extraction.get_fixtures(full_data)


if constants.RUN_DATA_EXPECTATIONS:
    validation_results = validate_data(full_data, data_expectations)





transformers = s3_helpers.load_transformer_s3_pickle(
    constants.TRANSFORMER_PATH,
    is_transformer = True
)


transformed_data = preprocessing.transform_data(
    full_data, transformers
)





classifier = s3_helpers.load_transformer_s3_pickle(
    constants.CLASS_MODEL_NAME,
    is_transformer = False
)


predictions = prediction.predict(transformed_data, classifier)


transformed_data['match_prediction'] = predictions





regressor_1 = s3_helpers.load_transformer_s3_pickle(
    constants.HOME_MODEL_NAME,
    is_transformer = False
)


predictions_1 = prediction.predict(transformed_data, regressor_1)


predictions_1[0:5]





regressor_2 = s3_helpers.load_transformer_s3_pickle(
    constants.AWAY_MODEL_NAME,
    is_transformer = False
)


predictions_2 = prediction.predict(transformed_data, regressor_2)


predictions_2[0:10]





transformed_data[transformed_data['HomeTeam'] == 'Brighton'].tail()


results = visualisations.extract_last_results('Brighton', transformed_data)


transformed_data['Home Prediction'] = predictions_1
transformed_data['Away Prediction'] = predictions_2
transformed_data['Result Prediction'] = transformed_data.apply(
    prediction.add_res_prediction, axis = 1)
s3_helpers.save_data_s3(transformed_data, constants.PREDICTIONS_LOCATION)


transformed_data['Result Prediction'].value_counts()


transformed_data.head(2)


current_fixtures = data_extraction.extract_current_fixtures(
    transformed_data
)
current_fixtures.head()





importlib.reload(mlflow_functions)


#Â Start postgresDB for model logging
if postgres.get_instance_status(
        constants.POSTGRES_DB_ID) != 'available':
    postgres.start_rds_instance(constants.POSTGRES_DB_ID)


mlflow_functions.open_mlflow_tracking(
    constants.EXP_NAME
)


client = MlflowClient()


print(mlflow_functions.get_all_experiments(
    client
))


runs = mlflow_functions.get_runs_from_experiment(
    client, experiment_id=1
)


run_df = mlflow_functions.runs_to_dataframe(
    mlflow_functions.get_runs_from_experiment(
    client, experiment_id=1
))


run_df





table = current_fixtures[['Fixture Date', 'Fixture Time', 'Location', 'HomeTeam', 'AwayTeam', 
                  'Home Prediction', 'Away Prediction' ,'Result Prediction']].reset_index(drop=True)
print(tabulate(table, tablefmt='fancy_grid', headers='keys'))


table = current_fixtures[['HomeTeam', 'AwayTeam', 
                  'Home Prediction', 'Away Prediction']].reset_index(drop=True)
table.index = table.index + 1
print(tabulate(table, tablefmt='fancy_grid', headers='keys'))


# Example of extract last 5
#importlib.reload(visualisations)
results = visualisations.extract_last_results('Brentford', transformed_data)


classifier


transformed_data.head()


# Shap values
explainer = shap.TreeExplainer(regressor_1)
shap_values = explainer.shap_values(transformed_data[regressor_1.feature_names_])


shap.summary_plot(
        shap_values, 
        transformed_data[regressor_1.feature_names_],
        plot_type = 'bar'
)


# Loop through each class and create a summary plot
shap.summary_plot(
        shap_values, 
        transformed_data[regressor_1.feature_names_], 
        show=False
)
plt.title('Home Team Goals')
plt.show()


# Loop through each class and create a summary plot
shap.summary_plot(
        shap_values, 
        transformed_data[regressor_2.feature_names_], 
        show=False
)
plt.title('Away Team Goals')
plt.show()


shap.dependence_plot(
    'DiffPts', 
    shap_values, 
    transformed_data[regressor_1.feature_names_]
)


shap.dependence_plot(
    'HomeTeam', 
    shap_values, 
    transformed_data[regressor_1.feature_names_]
)


shap.dependence_plot(
    'HTGD', 
    shap_values, 
    transformed_data[regressor_1.feature_names_]
)



